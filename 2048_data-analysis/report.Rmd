---
title: "Heuristics for 2048 : Data Visulisation"
output: html_document
date: "August 2024"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,out.width="100%")
library(tidyverse)
library(viridis)
library(knitr)
library(ggpubr)
bot_data <- read_csv("~/coding projects/2048/bot_data.csv")
direction_labs <- c("Control", "Down","Left","Mixed","Right","Up")
```

# Introduction

This document compares the results of 17 differently weighted bots playing the game "2048". The version of 2048 used to collect this data was originally written by me in Haskell. All the bots work in the same way, by picking their next move at random. However the weighting applied results in different bots favouring different directions. Each direction has one of: <br></br>
 - no particular preference (weight = 1)<br></br>
 - a weak preference (weight = 5)<br></br>
 - a strong preference (weight = 10)<br></br>
 Each combination of preference was repeated 50 times, and with the score on every turn recorded, until the game was finished. In order to do this, I used Python to repeated call the Haskell executable (which runs in terminal).

# Raw Data Summary
Below is the raw data collected after all 17 of the bots had finished their 50 attempts at playing the game. The 7 columns contain the following information: <br></br>
 - Bot id : First character indicates which weight combination is being  used, the number indicates it is the xth attempt with this weight combination<br></br>
 - Turn no. : The turn the bot is on in that attempt<br></br>
 - Current Score : The total score on each turn <br></br>
 - Up/Left/Down/Right weight : How much of a preference is given to each direction (numbers explained above)<br></br>

```{r raw data summary table}
knitr :: kable(summary(bot_data),"simple")
```

# Expanding the table

We can now add a few columns to add some extra information for when we start making charts:<br></br>
 - lastTurn : Bool which says whether that turn is the bots last turn in a game<br></br>
 - weightClass: column containing the character from Bot id<br></br>
 - prefStrength: Strength of preference (Strong = at least one weight is 25, Weak = largest weighting is 5, Control = all weights are 1)<br></br>
 - Direction: If only one direction has a weighting larger than 1, that direction will appear in this column. If 2 directions have a weighting larger than 1, it's classed as M(ixed). If all directions are 1, it is classed as C(ontrol). The strength of the preference is virtually ignored here. <br></br>
 - comboOrSingle - generalisation of the Direction column, single means only one direction has a preference, combo means multiple directions have a preference<br></br>
The pairings of the mixed combinations of directions are Up/Left, and Down/Right

```{r create all needed columns + display table}
allCols <- bot_data %>% 
            mutate(lastTurn = case_when(lead(`Bot id`) == `Bot id` ~ FALSE,
                           TRUE ~ TRUE)) %>% 
            mutate(weightClass = substr(`Bot id`,1,1)) %>% 
            mutate( prefStrength = case_when(`up weight`== 25 | `down weight` == 25
                                         | `left weight` == 25 | `right weight` == 25 ~ "Strong",
                                         `up weight`== 5 | `down weight` == 5
                                       | `left weight` == 5 | `right weight` == 5 ~ "Weak",
                                         TRUE ~ "Control")) %>% 
            mutate(Direction = case_when(`up weight` > `down weight` & `left weight` == 1 ~ "U",
                              `down weight` > `up weight` & `right weight` == 1 ~ "D",
                              `left weight` > `right weight` & `up weight` == 1 ~ "L",
                              `right weight` > `left weight` & `down weight` == 1 ~ "R",
                              `up weight` != `down weight` ~ "M",
                               TRUE ~ "C")) %>% 
            mutate(comboOrSingle = case_when(`up weight` != `down weight` & 
                                               `left weight` != `right weight` ~ "Combo",
                                               `up weight` == `down weight` & 
                                               `left weight` == `right weight` ~ "Control",
                                                TRUE ~ "Single"))
  
knitr :: kable(head(allCols),"simple",
               caption="<font color='black' size=5>Start of the overall table</font>",)
```

We also create a table which only contains the final scores for each bots attempt, as a lot of visulisations are primarily interested in this, and not the journey to the score

```{r filtered for only final scores}
final_scores <- allCols %>% 
    filter(lastTurn) %>% 
     select(-lastTurn) %>% 
      rename(finalScore = `Current score`, Turns = `Turn no.`)
knitr :: kable(head(final_scores),"simple",
               caption="<font color='black' size=5>Additional table, housing final scores</font>",)
```


```{r summary/boxplot functions}
# We define some functions to make the plotting of similar graphs easier

make_summary_table <- function(data,col) {
    summarize(data,Mean = mean(.data[[col]]),
            Median = median(.data[[col]]),
            LQ = quantile(.data[[col]],0.25),
            UQ = quantile(.data[[col]],0.75),
            Max = max(.data[[col]]),
            Min = min(.data[[col]]),
            SD  = sd(.data[[col]]))
}

make_boxplot <- function(data,xaxis,yaxis,colour,show_legend = TRUE) {
ggplot(data,aes_string(x=xaxis,y=yaxis)) + 
  geom_boxplot(aes_string(color=colour),show.legend = show_legend,lwd=1,fatten=1) + 
  theme_minimal() +
  scale_color_viridis(discrete = TRUE,option="D") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14)) 
}
```

# General observations

Firstly, we just look a general pattern in the data, between final score and the number of turns
```{r final score vs num turns scatter}

finalScoreVsTurns <- ggplot(final_scores,aes(x=finalScore,y=Turns)) +
  geom_point(aes(color=prefStrength)) + theme_minimal() +
  labs(x="Final Score",
       y= "Number of Turns",
       color="Strength of preference") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14)) + 
  scale_colour_viridis_d()

finalScoreVsTurns + stat_cor(digits=3) +labs(title="Final score vs number of turns")

finalScoreVsTurns + xlim(250,2000) + ylim(50,225) +labs(title="Snapshot of main graph (scores between 250-2000)")

```

As we would expect, there is a very strong linear relationship between score and number
of turns since the bots need to keep scoring in order to keep the board empty, and
keep playing. However, it is interesting to note that for some scores, there can a 
very wide range of the number of turns it took to get there. For example for scores 
just past 2000, it can take the bots anywhere between ~180-215 turns to get there.

For some of the highest scores, it's particularly interesting to see that roughly the
same number of turns (in this case ~350) can lead to a fairly wild range of final scores,
in this case, from ~3800-4750.

From these scatters we can also see that it tends to be 
that the bots with a strong preference for some direction have the highest scores.
Even in scores between 250-2000, the top end is dominated by the bots with 
strong preference. However it should be noted that there is a large spread in scores
no matter the preference, with some of the lowest scores achieved by a bot 
with a strong preference. This will be looked at further in another section.  

<br></br>
<br></br>

We can also look at the progression of the score for the best performing bot,
which achieved a final score of 5176 in 390 turns. This bot was given a strong 
preference for both going down and right. 

```{r best score progress tracking graphs}
best_score <- top_n(final_scores,1,finalScore)
top_score <- best_score$`Bot id`

best_perf <- allCols %>% 
  filter(,`Bot id` == top_score) %>% 
  mutate(score_gained_on_move = `Current score` - lag(`Current score`))

ggplot(best_perf,aes(x=`Turn no.`,y=score_gained_on_move)) + geom_line(colour="blue",lwd=0.8) +
  theme_minimal() + labs(x="Turn number",y="Points gained on turn",
                         title="Points gained per turn for the best performing bot") +
theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14)) 

ggplot(best_perf, aes(x = `Turn no.`, y=`Current score`)) +
  geom_line(colour="blue",lwd=1) +
  labs(x = "Turn number", y = "Score",
       title = "Progression of the score for the best performing bot") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14)) 

```

Using these graphs we can spot where some high scoring tiles were combined, with the largest
peak/jump being 512 (the largest tile obtained by the bot), and the two other large peaks both 
being 256. The spread of large advancements in fairly evenly spread, as would be expected since
the bot needs to build up to them. We can also see that the rate of progression in the flatter 
sections is roughly the same throughout.

<br></br>

```{r bar chart of bots surpassing nums of turns}
counts = c(50,100,150,200,250,300,350,400)

inter <- allCols %>% 
  group_by(`Turn no.`) %>% 
  summarize(count = n()) %>% ungroup() %>% 
  filter(`Turn no.` %in% counts) %>% 
  right_join(data.frame("Turn no." = counts,check.names = FALSE),by="Turn no.") %>% 
  replace(is.na(.),0)

ggplot(inter,aes(x=`Turn no.`,y=count)) +
  geom_col(aes(fill=as.factor(`Turn no.`)),colour="black",show.legend=FALSE) +
   theme_minimal() + xlim(0,400) +
  labs(x="Turn Number",y="Number of bots making it to that turn",
       title = "Bar chart to see how many turns each bot made it through") +
  scale_fill_viridis(discrete = TRUE, option = "D") 
```

From this bar chart we can see the drop-off in the percentage of bots getting past a certain number of turns. The greatest drop-off occurs between 100 and 150 turns, and 150 and 200 turns. This makes a lot of sense, since as we can see the mean number of turns is 151.3. This chart reinforces the fact that very few bots managed to make it past 300 turns.

# Directional Preference
In this section we see if direction had an effect on the success of the bots (here we generally do not worry about the strength of the preference in each direction). We would expect that the single directions should all have roughly equivalent performance, since the board is symmetric. 

```{r final score per direction summary table}
dir_finalscore_summary <- final_scores %>% 
  group_by(Direction) %>% 
  make_summary_table("finalScore") %>% 
    mutate(Direction = direction_labs)
  
knitr :: kable(dir_finalscore_summary,"simple",digits=2,
               caption="<font color='black' size=5>Summary stats based on final score</font>")
```

Just by looking at the summary table we can see that the four solo directions were fairly similar, with Up being the weakest. Down and Left, also have fairly high standard deviations compare to the Right and Up. However in most respects these four lived up to the expectations, and were fairly similar, something which is even more apparent in the boxplots below. The mixed directions clearly far outperformed all the other combinations.

```{r direction vs final score boxplot}

dirVsFinalScoreO <- make_boxplot(final_scores,"Direction","finalScore","Direction",show_legend = FALSE)
dirVsFinalScoreO +
      labs(x="Directional Preference", y = "Final Score",
       title = "Final score based on directional preference (overall)")

dirVsFinalScoreS <- make_boxplot(final_scores,"Direction","finalScore","prefStrength")
dirVsFinalScoreS +
    labs(x="Directional Preference", y = "Final Score",
       title="Final score based on directional preference (by strength)",
       color="Strength of preference") +
  scale_x_discrete(labels = direction_labs)

```

In these two graphs we see even more clearly that the performance of the four solo directions is very similar, with their boxplots looking almost the same. The control bot where all 4 directions had equal weighting seemingly tended to do the worst, whilst mixed combinations outperformed all other bots including with the most high-valued outliers.

Looking at the second graph, we see that no matter the direction chosen, the bots with a stronger preference tended to do much better than those with a weaker preference. Interestingly though, Left and Right were better by a large margin, whilst Up and Down were only slightly better on a stronger preference.

<br></br>

Now we move to see the effect each directional preference on the number of turns the bots lasted. Although this is not the metric we particularly care about (a long, low scoring game is not as good as a short, fast scoring game), from above we see that there is a strong correlation between number of turns and score, so a game with lots of turns is likely to have been very successful.

```{r num of turns per direction summary table}
dir_turns_summary <- final_scores %>% 
  group_by(Direction) %>% 
   make_summary_table("Turns") %>% 
    mutate(Direction = direction_labs)

knitr :: kable(dir_turns_summary,"simple",digits=2,
               caption="<font color='black' size=5>Summary stats based on number of turns</font>")
```

As in the case for the final score, here again we see than the four solo directions were all fairly similar in terms of their performance, with Up still being the weakest. Mixed combinations also came out on top in this metric, althought its standard deviation was more similar to the other categories this time.

```{r direction vs num turns boxplot}

dirVsTurnsO <- make_boxplot(final_scores,"Direction","Turns","Direction",show_legend = FALSE)
dirVsTurnsO + 
  labs(x="Directional Preference", y = "Number of turns",
       title = "Number of turns based on directional preference (overall)") + 
  scale_x_discrete(labels = c("Control", "Down","Left","Mixed","Right","Up"))

dirVsTurnsS <- make_boxplot(final_scores,"Direction","Turns","prefStrength")
dirVsTurnsS + 
  labs(x="Directional Preference", y = "Number of turns",
       title = "Number of turns based on directional preference (by strength)") + 
  scale_x_discrete(labels = c("Control", "Down","Left","Mixed","Right","Up"))
```

We can see that the graphs for the number of turns and final score are very similar
visually, with the difference between them only really clear when you look at the
scale. This obviously follows from there being a very strong linear correlation
between these two variables, as mentioned earlier. We will also see this pattern repeating the section looking at the effect of the strength of the preference.

# Strength Preference

In this section we change our focus to see if the strength of the preference has an impact on the score. We mainly compare a weak preference (max 5 in any direction), with a strong preference(25 in some direction), of course alongside the completely random bot.

```{r final score by strength summary table}
strength_finalscore_summary <- final_scores %>% 
  group_by(prefStrength) %>% 
  make_summary_table("finalScore")  %>% 
  rename(`Strength of Preference` =prefStrength)

knitr :: kable(strength_finalscore_summary,"simple",digits=2,
               caption="<font color='black' size=5>Summary stats based on final score</font>")
```

From this table we see that a strong preference comes out superior in virtually every metric, although it does have a much larger spread of values. It's mean score is over 300 points larger than that of the bots with a weak preference, although this is probably helped by a couple of very large scores achieved by the strong preference bots. Interestingly though, the strong preference bots also achieved the lowest minumum score of just 228.


```{r strength vs final score boxplots}

strengthVsScoreO <- make_boxplot(final_scores,"prefStrength","finalScore","prefStrength",show_legend = FALSE)
strengthVsScoreO + labs(x="Strength of Preference", y = "Final Score",
                        title ="Final scores for different strengths of preference (overall)")  

strengthVsScoreD <- make_boxplot(final_scores,"prefStrength","finalScore","Direction")
strengthVsScoreD + labs(x="Strength of Preference", y = "Final Score",
                        title ="Final scores for different strengths of preference (by direction)")

```

From these boxplots we see that on average, the weak bots weren't much better than the control bots, although we see they were far more likely to actually reach higher scores from the number of outliers. Clearly though, on average the strong preference bots were head and shoulders above the others, and achieved the vast majority of large scores, as see in all the high outliers.

From the second graph we see that the best perfoming bots tended to be the bots with a strong, mixed preference for diection.

<br></br>
Similarly to direction, we will also now look at a comparison of the number of turns achieved in the games by bots with different strengths of preferences

```{r num of turns by strength summary table}
strength_turns_summary <- final_scores %>% 
  group_by(prefStrength) %>% 
  make_summary_table("Turns")

knitr :: kable(strength_turns_summary,"simple",digits=2,
               caption="<font color='black' size=5>Summary stats based on number of turns</font>")
```

Echoing the summary from earlier, strong preference bots have outperformed the other bots by a fairly larger margin, with a mean number of turns 30 greater than either of the other two. However their spread of how many turns each game took was much larger, and a strong preference bot also had the shortest game of just 47 turns. 

```{r number of turns by strength box plots}
strengthVsTurnsO <- make_boxplot(final_scores,"prefStrength","Turns","prefStrength",show_legend = FALSE)
strengthVsTurnsO +labs(x="Strength of Preference", y = "Number of Turns",
                       title ="Number of turns for different strengths of preference (overall)") 

strengthVsTurnsD <- make_boxplot(final_scores,"prefStrength","Turns","Direction")
strengthVsTurnsD + labs(x="Strength of Preference", y = "Number of turns",
                        title ="Number of turns for different strengths of preference (by direction)") 
```

As noted earlier these box plots are very similar to those for final score, with the only noticeable different being in the scale. Mixed combination bots prevail in both strong and weak preferences. WE can see that there is a bit of a spread between the different solo directions, with some seeming to perform better than others. Interestingly, Up and Down seem to be the worst when it comes to strong preference bots, but then some of the best on the weak preference bots. However this may just be something that would be ironed out if we ran the bots for more than 50 times each.


# Combination vs Solo preference

Finally we compare the performance of the bots which had a preference for only 
one direction with the bots which had a preference for two directions (the pairings being
up/left and down/right).

```{r final score per combo summary table}
combo_finalscore_summary <- final_scores %>% 
  group_by(comboOrSingle) %>% 
  make_summary_table("finalScore") %>% 
   slice(2,1,3) %>% rename(`Button combination` = comboOrSingle )

knitr :: kable(combo_finalscore_summary,"simple",digits = 2,
               caption="<font color='black' size=5>Summary stats based on final score</font>")

combo_turns_summary <- final_scores %>% 
  group_by(comboOrSingle) %>% 
  make_summary_table("Turns") %>% 
  slice(2,1,3) %>% rename(`Button combination` = comboOrSingle )

knitr :: kable(combo_turns_summary,"simple",digits = 2,
               caption="<font color='black' size=5>Summary stats based on number of turns</font>")
```
 
From the summary tables we see that the bots with a combination of preferences generally outperform the other bots in both number of turns and final score. The tables here are extremely similar to those for strength of preference, with nearly identical means for combo/strong preferences and single/weak preferences. (The group of control bots are in fact the same)  
 
```{r combo vs final score box plot}
final_scores$comboOrSingle <- factor(final_scores$comboOrSingle,levels=c("Control","Combo","Single"))

comboVsScore <- make_boxplot(final_scores,"comboOrSingle","finalScore","comboOrSingle",show_legend = FALSE)
comboVsScore +
  labs(x="Button Combination",y = "Final Score",
       title ="Final score achieved by different button combinations") 
```
 
Practically all the scores over 3250 were achieved by bots with a combination of preferences. We can easily see here that the button with just a single directional preference were not much better than the completely random bots on average, although were better at more consistently achieving a score greater than 2500. The greatest spread of results appears in the combo bots, with their worst score lower than that of the control bots.
 
```{r line chart comparing max strength combo bots final scores}
max_strength <- final_scores %>% 
  filter(comboOrSingle == "Combo" & ((`up weight` == 25 & `left weight` == 25) |
                                       (`down weight` == 25 & `right weight` == 25))) %>% 
  mutate(dir = case_when(`up weight` != 1 ~ "U/L",
                         `down weight` != 1 ~ "D/R")) %>% 
  mutate(bot_num = as.numeric(substr(`Bot id`,start=2,stop=nchar(`Bot id`))))
  
comparison <- left_join(filter(max_strength, dir == "D/R"),filter(max_strength, dir == "U/L"),by="bot_num") %>% 
  mutate(DRBigger = finalScore.x >= finalScore.y )

value_counts <- table(comparison$DRBigger)
DRBigger <- value_counts['TRUE']
notDRBigger <- value_counts['FALSE']

ggplot(max_strength,aes(x=bot_num,y=finalScore,colour=dir)) + geom_line(lwd=0.8) +
  labs(x="Bot number",
       y = "Final score",
       title = "Final score comparison for the combo bots \n(with max preference in both directions)",
       color="Direction combinations",) + theme_minimal() + 
  scale_colour_brewer(palette="Dark2", labels=c("Down and Right", "Up and Left")) + 
  annotate("text",x=c(30,30,30),y = c(4900,4650,4350),label=c("Bot by bot comparison:",
                                                              paste("D/R larger : ", DRBigger),
                                                              paste("U/L larger : ", notDRBigger)))

```

Here we can see a comparison of the two different types of combo bots we used, with the combination of Down and Right in green, and Up and Left in red. Their results are fairly similar, as we would expect since they should just be symmetric versions of one another. Both achieve a few high points, and their fair share of lower scores too. On the whole, U/L was slightly better on a bot by bot basis, but this mainly depends on the performance of that numbered bot, rather than any general indications as to trends.

## Conclusion 

waffle